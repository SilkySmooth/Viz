<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Music Visualizer</title>
    <style>
        body { margin: 0; font-family: Arial, sans-serif; background: #222; color: #fff; }
        #container { position: relative; width: 100vw; height: 100vh; display: flex; justify-content: center; align-items: center; }
        #canvas { background: #333; }
        #controls { position: absolute; top: 10px; left: 10px; background: rgba(0, 0, 0, 0.7); padding: 10px; border-radius: 5px; }
        #controls label { margin-right: 10px; }
        #playRecordBtn { padding: 10px; background: #28a745; border: none; color: #fff; cursor: pointer; border-radius: 5px; }
        #playRecordBtn:hover { background: #218838; }
        #playRecordBtn:disabled { background: #555; cursor: not-allowed; }
        #error { color: #ff5555; margin-top: 10px; }
        #status { color: #55ff55; margin-top: 10px; }
    </style>
</head>
<body>
    <div id="container">
        <canvas id="canvas"></canvas>
        <div id="controls">
            <label>Audio (WAV):</label><input type="file" id="audioInput" accept=".wav"><br>
            <label>Images (PNG/JPEG):</label><input type="file" id="imageInput" accept="image/png,image/jpeg,image/jpg" multiple><br>
            <label>Mode:</label>
            <select id="modeSelect">
                <option value="wide">Wide (16:9)</option>
                <option value="tall">Tall (9:16)</option>
            </select><br>
            <button id="playRecordBtn" disabled>Play & Record</button>
            <div id="error"></div>
            <div id="status"></div>
        </div>
    </div>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script>
        const canvas = document.getElementById('canvas');
        const audioInput = document.getElementById('audioInput');
        const imageInput = document.getElementById('imageInput');
        const modeSelect = document.getElementById('modeSelect');
        const playRecordBtn = document.getElementById('playRecordBtn');
        const errorDiv = document.getElementById('error');
        const statusDiv = document.getElementById('status');

        let scene, camera, renderer, textures = [], meshes = [], audioCtx, source, analyser, audioBuffer;
        let currentImageIndex = 0, transitionStartTime = 0, transitionDuration = 1;
        let isPlaying = false, isRecording = false, mediaRecorder, chunks = [];
        let transitionInterval = 5; // Default, updated after audio load
        let aspectMode = 'tall';
        let planeWidths = []; // Store width of each plane for positioning

        function initWebGL() {
            scene = new THREE.Scene();
            renderer = new THREE.WebGLRenderer({ canvas, antialias: true });
            renderer.setClearColor(0x000066);
            updateCanvasSize();
            camera = new THREE.PerspectiveCamera(60, canvas.width / canvas.height, 0.1, 1000);
            camera.position.set(0, 0, 10);
            console.log('WebGL initialized');
        }

        function updateCanvasSize() {
            const container = document.getElementById('container');
            const maxWidth = container.clientWidth, maxHeight = container.clientHeight;
            const targetAspect = aspectMode === 'wide' ? 16 / 9 : 9 / 16;
            canvas.width = aspectMode === 'wide' ? 1920 : 1080;
            canvas.height = aspectMode === 'wide' ? 1080 : 1920;
            const scale = Math.min(maxWidth / canvas.width, maxHeight / canvas.height);
            canvas.style.width = `${canvas.width * scale}px`;
            canvas.style.height = `${canvas.height * scale}px`;
            renderer.setSize(canvas.width, canvas.height);
            if (camera) {
                camera.aspect = targetAspect;
                camera.updateProjectionMatrix();
            }
            console.log(`Canvas resolution: ${canvas.width}x${canvas.height}, Aspect: ${targetAspect}, Display: ${canvas.style.width}x${canvas.style.height}`);
        }

        function loadImageTextures(files) {
            textures = [];
            meshes = [];
            planeWidths = [];
            let loaded = 0, validImages = 0;
            const totalFiles = files.length;
            errorDiv.textContent = '';
            statusDiv.textContent = `Loading ${totalFiles} image(s)...`;
            let cumulativeX = 0; // Track position for edge-to-edge placement
            Array.from(files).forEach((file, index) => {
                if (!file.type.match(/image\/(png|jpeg|jpg)/)) {
                    errorDiv.textContent += `Skipping ${file.name}: Unsupported format\n`;
                    console.error(`Skipping ${file.name}: Unsupported format`);
                    loaded++;
                    if (loaded === totalFiles) checkReady();
                    return;
                }
                if (file.size > 10 * 1024 * 1024) {
                    errorDiv.textContent += `Skipping ${file.name}: File too large (>10MB)\n`;
                    console.error(`Skipping ${file.name}: File too large`);
                    loaded++;
                    if (loaded === totalFiles) checkReady();
                    return;
                }
                const reader = new FileReader();
                reader.onload = (e) => {
                    const img = new Image();
                    img.src = e.target.result;
                    img.onload = () => {
                        if (img.width === 0 || img.height === 0) {
                            errorDiv.textContent += `Error: ${file.name} has invalid dimensions\n`;
                            console.error(`Invalid dimensions for ${file.name}`);
                            loaded++;
                            if (loaded === totalFiles) checkReady();
                            return;
                        }
                        const texture = new THREE.Texture(img);
                        texture.needsUpdate = true;
                        textures.push(texture);
                        const imgAspect = img.width / img.height;
                        const canvasAspect = aspectMode === 'wide' ? 16 / 9 : 9 / 16;
                        let planeWidth = 10;
                        let planeHeight = planeWidth / imgAspect;
                        if (imgAspect > canvasAspect) {
                            planeHeight = planeWidth / canvasAspect;
                        } else {
                            planeWidth = planeHeight * canvasAspect;
                        }
                        const geometry = new THREE.PlaneGeometry(planeWidth, planeHeight);
                        const material = new THREE.MeshBasicMaterial({
                            map: texture,
                            color: 0xffffff,
                            side: THREE.DoubleSide
                        });
                        const mesh = new THREE.Mesh(geometry, material);
                        // Position mesh so images are edge-to-edge
                        mesh.position.x = cumulativeX + planeWidth / 2; // Center of current image
                        cumulativeX += planeWidth; // Move to right edge for next image
                        planeWidths.push(planeWidth);
                        scene.add(mesh);
                        meshes.push(mesh);
                        validImages++;
                        loaded++;
                        console.log(`Loaded image ${index + 1}/${totalFiles}: ${file.name}, ${img.width}x${img.height}, Aspect: ${imgAspect}, Plane: ${planeWidth}x${planeHeight}, Position: ${mesh.position.x}`);
                        statusDiv.textContent = `Loaded ${validImages}/${totalFiles} image(s)`;
                        if (loaded === totalFiles) checkReady();
                    };
                    img.onerror = () => {
                        errorDiv.textContent += `Error loading image ${file.name}\n`;
                        console.error(`Failed to load image ${file.name}`);
                        loaded++;
                        if (loaded === totalFiles) checkReady();
                    };
                };
                reader.onerror = () => {
                    errorDiv.textContent += `Error reading file ${file.name}\n`;
                    console.error(`FileReader error for ${file.name}`);
                    loaded++;
                    if (loaded === totalFiles) checkReady();
                };
                reader.readAsDataURL(file);
            });
        }

        async function loadAudio(file) {
            try {
                console.log('Starting audio load:', file.name);
                audioCtx = audioCtx || new (window.AudioContext || window.webkitAudioContext)();
                console.log('AudioContext created');
                const arrayBuffer = await file.arrayBuffer();
                audioBuffer = await audioCtx.decodeAudioData(arrayBuffer);
                analyser = audioCtx.createAnalyser();
                analyser.fftSize = 256;
                console.log('Audio loaded successfully, duration:', audioBuffer.duration);
                if (textures.length > 0) {
                    transitionInterval = audioBuffer.duration / textures.length;
                    console.log(`Transition interval set to ${transitionInterval}s for ${textures.length} images`);
                }
                statusDiv.textContent = 'Audio loaded';
                checkReady();
            } catch (err) {
                errorDiv.textContent = 'Error loading audio: ' + err.message;
                console.error('Audio load error:', err);
            }
        }

        function checkReady() {
            if (audioBuffer && audioCtx && textures.length > 0) {
                playRecordBtn.disabled = false;
                errorDiv.textContent = '';
                statusDiv.textContent = `Ready: ${textures.length} image(s), audio duration: ${audioBuffer.duration}s`;
                console.log(`Ready to play: ${textures.length} images, audio duration: ${audioBuffer.duration}s`);
                if (audioBuffer && textures.length > 0) {
                    transitionInterval = audioBuffer.duration / textures.length;
                    console.log(`Transition interval set to ${transitionInterval}s for ${textures.length} images`);
                }
            } else {
                playRecordBtn.disabled = true;
                errorDiv.textContent = `Not ready: Audio ${audioCtx ? (audioBuffer ? 'loaded' : 'missing buffer') : 'missing context'}, Images: ${textures.length}`;
                console.log(`Not ready: Audio ${audioCtx ? (audioBuffer ? 'loaded' : 'missing buffer') : 'missing context'}, Images: ${textures.length}`);
            }
        }

        function animate() {
            requestAnimationFrame(animate);
            if (!isPlaying) return;

            const time = audioCtx.currentTime;
            if (time - transitionStartTime >= transitionInterval) {
                currentImageIndex = (currentImageIndex + 1) % textures.length;
                transitionStartTime = time;
                console.log(`Transition to image ${currentImageIndex + 1}/${textures.length} at ${time.toFixed(2)}s, Camera X: ${camera.position.x.toFixed(2)}`);
                statusDiv.textContent = `Playing: Image ${currentImageIndex + 1}/${textures.length}`;
            }

            const progress = Math.min((time - transitionStartTime) / transitionDuration, 1);
            const targetX = meshes[currentImageIndex].position.x; // Move to center of current image
            camera.position.x = THREE.MathUtils.lerp(camera.position.x, targetX, progress * 0.1); // Smooth transition
            camera.rotation.y = 0; // No rotation

            renderer.render(scene, camera);
        }

        function getSupportedMimeType() {
            const types = [
                'video/mp4;codecs=avc1',
                'video/webm;codecs=h264',
                'video/webm;codecs=vp9',
                'video/webm'
            ];
            for (const type of types) {
                if (MediaRecorder.isTypeSupported(type)) {
                    console.log(`Selected MIME type: ${type}`);
                    return type;
                }
            }
            console.error('No supported video codecs found');
            return null;
        }

        async function startPlaybackAndRecording() {
            console.log('Play & Record clicked');
            if (isPlaying) {
                isPlaying = false;
                source.stop();
                if (isRecording) {
                    mediaRecorder.stop();
                    isRecording = false;
                }
                playRecordBtn.textContent = 'Play & Record';
                console.log('Playback stopped');
                statusDiv.textContent = '';
                return;
            }

            if (!audioCtx || !audioBuffer || textures.length === 0) {
                errorDiv.textContent = 'Cannot play: Missing audio or images';
                console.error('Cannot play: Missing resources', { audioCtx: !!audioCtx, audioBuffer: !!audioBuffer, textures: textures.length });
                return;
            }

            try {
                isPlaying = true;
                source = audioCtx.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(analyser);
                analyser.connect(audioCtx.destination);
                source.onended = () => {
                    if (isPlaying) {
                        isPlaying = false;
                        if (isRecording) {
                            mediaRecorder.stop();
                            isRecording = false;
                        }
                        playRecordBtn.textContent = 'Play & Record';
                        console.log('Audio ended, recording stopped');
                        statusDiv.textContent = 'Recording saved';
                    }
                };
                source.start();
                console.log('Playback started');
                statusDiv.textContent = 'Playing and recording...';

                const canvasStream = canvas.captureStream(60);
                const audioDest = audioCtx.createMediaStreamDestination();
                source.connect(audioDest);
                const audioStream = audioDest.stream;
                const combinedStream = new MediaStream([
                    ...canvasStream.getVideoTracks(),
                    ...audioStream.getAudioTracks()
                ]);
                const mimeType = getSupportedMimeType();
                if (!mimeType) {
                    throw new Error('No supported video codecs found');
                }
                mediaRecorder = new MediaRecorder(combinedStream, { 
                    mimeType,
                    videoBitsPerSecond: 8000000 // Set bitrate to 8 Mbps
                });
                chunks = [];
                mediaRecorder.ondataavailable = (e) => {
                    if (e.data.size > 0) chunks.push(e.data);
                    console.log('Recording data received:', e.data.size);
                };
                mediaRecorder.onstop = () => {
                    console.log('Recording stopped, saving video');
                    try {
                        const blob = new Blob(chunks, { type: 'video/mp4' });
                        const url = URL.createObjectURL(blob);
                        const a = document.createElement('a');
                        a.href = url;
                        a.download = 'music_visualizer.mp4';
                        a.click();
                        URL.revokeObjectURL(url);
                        console.log('Video saved');
                        statusDiv.textContent = 'Video saved';
                    } catch (err) {
                        errorDiv.textContent = 'Error saving video: ' + err.message;
                        console.error('Save error:', err);
                    }
                };
                mediaRecorder.onerror = (e) => {
                    errorDiv.textContent = 'Error saving: ' + e.error.message;
                    console.error('Recording error:', e.error);
                };
                mediaRecorder.start();
                isRecording = true;
                playRecordBtn.textContent = 'Stop & Save';
                console.log('Recording started with', mimeType, 'at 8 Mbps');

                currentImageIndex = 0; // Start from first image
                transitionStartTime = audioCtx.currentTime;
                camera.position.x = meshes[0].position.x; // Initialize camera at first image
                animate();
            } catch (err) {
                errorDiv.textContent = 'Error starting playback: ' + err.message;
                console.error('Playback setup error:', err);
                isPlaying = false;
                playRecordBtn.textContent = 'Play & Record';
                statusDiv.textContent = '';
            }
        }

        audioInput.addEventListener('change', (e) => {
            if (e.target.files[0]) {
                errorDiv.textContent = '';
                statusDiv.textContent = 'Loading audio...';
                loadAudio(e.target.files[0]);
            }
        });

        imageInput.addEventListener('change', (e) => {
            if (e.target.files.length) {
                errorDiv.textContent = '';
                loadImageTextures(e.target.files);
            }
        });

        modeSelect.addEventListener('change', (e) => {
            aspectMode = e.target.value;
            updateCanvasSize();
            console.log('Mode changed to:', aspectMode);
        });

        playRecordBtn.addEventListener('click', startPlaybackAndRecording);

        initWebGL();
    </script>
</body>
</html>
